{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b935e02d-27d8-4b5e-b09e-3fc1e5569374",
   "metadata": {},
   "source": [
    "This project aims to develop a sentiment analysis system to classify text data as positive, negative, or neutral. Using a dataset of movie reviews, it preprocesses and converts text into numerical features with TF-IDF, then trains and evaluates Logistic Regression, Naive Bayes, and SVM models. Additionally, it provides a real-time sentiment analysis function for immediate sentiment feedback on new text inputs, showcasing the application of NLP and machine learning in extracting insights from textual data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6ef98c-e226-476b-9354-8b721df3b42f",
   "metadata": {},
   "source": [
    "Import Libraries and Download NLTK Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfb44901-933c-405a-b878-b45c30126831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff9d38c-80df-4ad3-a53a-4dd334dd756c",
   "metadata": {},
   "source": [
    "Download required NLTK datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1a0d833-0891-4cd2-9204-f34a378186c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/riteshgaire/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/riteshgaire/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/riteshgaire/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/riteshgaire/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('movie_reviews')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb64ce19-c1e3-4711-adac-29b82a8bdfc8",
   "metadata": {},
   "source": [
    "Load and Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7b2e69f-569b-4f01-acd5-09b68459b45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Review Sentiment\n",
      "0  plot two teen couple go church party drink dri...       neg\n",
      "1  happy bastard quick movie review damn y2k bug ...       neg\n",
      "2  movie like make jaded movie viewer thankful in...       neg\n",
      "3  quest camelot warner bros first feature length...       neg\n",
      "4  synopsis mentally unstable man undergoing psyc...       neg\n"
     ]
    }
   ],
   "source": [
    "# Load the movie reviews dataset from NLTK\n",
    "def load_movie_reviews():\n",
    "    documents = [(list(movie_reviews.words(fileid)), category)\n",
    "                 for category in movie_reviews.categories()\n",
    "                 for fileid in movie_reviews.fileids(category)]\n",
    "    return pd.DataFrame(documents, columns=['Review', 'Sentiment'])\n",
    "\n",
    "# Preprocess the data by cleaning the text\n",
    "def preprocess_data(df):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    punctuation = set(string.punctuation)\n",
    "\n",
    "    # Function to clean a single review\n",
    "    def clean_review(review):\n",
    "        # Lowercase the words\n",
    "        review = [word.lower() for word in review]\n",
    "        # Remove punctuation\n",
    "        review = [word for word in review if word not in punctuation]\n",
    "        # Remove stop words and lemmatize\n",
    "        review = [lemmatizer.lemmatize(word) for word in review if word not in stop_words]\n",
    "        return ' '.join(review)\n",
    "\n",
    "    # Apply cleaning to all reviews in the dataset\n",
    "    df['Review'] = df['Review'].apply(clean_review)\n",
    "    return df\n",
    "\n",
    "# Load and preprocess the data\n",
    "df = load_movie_reviews()\n",
    "df = preprocess_data(df)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe68a75-3a1d-46c1-8af1-15f280568261",
   "metadata": {},
   "source": [
    "Convert Text to Numerical Features (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9241f0df-691f-4681-abf5-7df42bb3d0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the text data to TF-IDF features\n",
    "def convert_to_tfidf(df):\n",
    "    vectorizer = TfidfVectorizer(max_features=3000)\n",
    "    X = vectorizer.fit_transform(df['Review']).toarray()\n",
    "    return X, df['Sentiment'], vectorizer\n",
    "\n",
    "# Convert the dataset\n",
    "X, y, vectorizer = convert_to_tfidf(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd74b470-4be8-4773-9c4b-97157f6169df",
   "metadata": {},
   "source": [
    "Split the Data and Train the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fa9398b-97c6-4cce-8707-70de8325bd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.815\n",
      "Logistic Regression Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.82      0.81      0.81       199\n",
      "         pos       0.81      0.82      0.82       201\n",
      "\n",
      "    accuracy                           0.81       400\n",
      "   macro avg       0.82      0.81      0.81       400\n",
      "weighted avg       0.82      0.81      0.81       400\n",
      "\n",
      "Naive Bayes Accuracy: 0.8\n",
      "Naive Bayes Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.78      0.83      0.81       199\n",
      "         pos       0.82      0.77      0.79       201\n",
      "\n",
      "    accuracy                           0.80       400\n",
      "   macro avg       0.80      0.80      0.80       400\n",
      "weighted avg       0.80      0.80      0.80       400\n",
      "\n",
      "SVM Accuracy: 0.81\n",
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.82      0.79      0.81       199\n",
      "         pos       0.80      0.83      0.81       201\n",
      "\n",
      "    accuracy                           0.81       400\n",
      "   macro avg       0.81      0.81      0.81       400\n",
      "weighted avg       0.81      0.81      0.81       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train and evaluate Logistic Regression model\n",
    "model_lr = LogisticRegression(max_iter=1000)\n",
    "model_lr.fit(X_train, y_train)\n",
    "y_pred_lr = model_lr.predict(X_test)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(\"Logistic Regression Classification Report:\\n\", classification_report(y_test, y_pred_lr))\n",
    "\n",
    "# Train and evaluate Naive Bayes model\n",
    "model_nb = MultinomialNB()\n",
    "model_nb.fit(X_train, y_train)\n",
    "y_pred_nb = model_nb.predict(X_test)\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(\"Naive Bayes Classification Report:\\n\", classification_report(y_test, y_pred_nb))\n",
    "\n",
    "# Train and evaluate SVM model\n",
    "model_svm = SVC(kernel='linear')\n",
    "model_svm.fit(X_train, y_train)\n",
    "y_pred_svm = model_svm.predict(X_test)\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"SVM Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9048cc-1d9a-4d3e-91d9-88cdfbc28d9f",
   "metadata": {},
   "source": [
    "Real-Time Sentiment Analysis Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01ef44ef-4897-4216-b600-6cc49a2cd02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos\n"
     ]
    }
   ],
   "source": [
    "# Function to analyze sentiment of new text input\n",
    "def analyze_sentiment(text, model, vectorizer):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    punctuation = set(string.punctuation)\n",
    "\n",
    "    # Function to clean a single review\n",
    "    def clean_review(review):\n",
    "        review = word_tokenize(review)\n",
    "        review = [word.lower() for word in review]\n",
    "        review = [word for word in review if word not in punctuation]\n",
    "        review = [lemmatizer.lemmatize(word) for word in review if word not in stop_words]\n",
    "        return ' '.join(review)\n",
    "\n",
    "    # Clean and vectorize the input text\n",
    "    processed_text = clean_review(text)\n",
    "    tfidf_text = vectorizer.transform([processed_text]).toarray()\n",
    "    sentiment = model.predict(tfidf_text)\n",
    "    return sentiment[0]\n",
    "\n",
    "# Example usage with Logistic Regression\n",
    "print(analyze_sentiment(\"This movie was absolutely fantastic!\", model_lr, vectorizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cc6c55-e3ac-4014-983a-ec22e68c19b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
